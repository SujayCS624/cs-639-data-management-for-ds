{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d804766-abb0-4cdf-bbb5-a14bf74f5f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: haystack-ai in /home/SujayCS/.local/lib/python3.10/site-packages (2.13.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (9.1.2)\n",
      "Requirement already satisfied: pydantic in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (2.11.1)\n",
      "Requirement already satisfied: tqdm in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (4.67.1)\n",
      "Requirement already satisfied: numpy in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (2.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.12.2)\n",
      "Requirement already satisfied: haystack-experimental in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (0.9.0)\n",
      "Requirement already satisfied: pyyaml in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (6.0.2)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from haystack-ai) (8.10.0)\n",
      "Requirement already satisfied: networkx in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (2.6.3)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.23.0)\n",
      "Requirement already satisfied: jinja2 in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (3.1.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.32.3)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (4.0.1)\n",
      "Requirement already satisfied: openai>=1.56.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (1.77.0)\n",
      "Requirement already satisfied: lazy-imports in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai) (0.4.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (2.9.0.post0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.56.1->haystack-ai) (1.3.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from openai>=1.56.1->haystack-ai) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.56.1->haystack-ai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.56.1->haystack-ai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.56.1->haystack-ai) (0.28.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from posthog!=3.12.0->haystack-ai) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from posthog!=3.12.0->haystack-ai) (1.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from pydantic->haystack-ai) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from pydantic->haystack-ai) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from pydantic->haystack-ai) (2.33.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->haystack-ai) (1.26.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->haystack-ai) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->haystack-ai) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->haystack-ai) (2.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->haystack-ai) (25.1.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->haystack-ai) (0.22.3)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->haystack-ai) (0.36.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->haystack-ai) (2024.10.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.56.1->haystack-ai) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai) (0.14.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: elasticsearch-haystack in /home/SujayCS/.local/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/SujayCS/.local/lib/python3.10/site-packages (from elasticsearch-haystack) (3.11.18)\n",
      "Requirement already satisfied: elasticsearch<9,>=8 in /home/SujayCS/.local/lib/python3.10/site-packages (from elasticsearch-haystack) (8.17.2)\n",
      "Requirement already satisfied: haystack-ai>=2.11.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from elasticsearch-haystack) (2.13.1)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from elasticsearch<9,>=8->elasticsearch-haystack) (8.17.0)\n",
      "Requirement already satisfied: numpy in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (2.2.2)\n",
      "Requirement already satisfied: pydantic in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (2.11.1)\n",
      "Requirement already satisfied: openai>=1.56.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (1.77.0)\n",
      "Requirement already satisfied: posthog!=3.12.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (4.0.1)\n",
      "Requirement already satisfied: lazy-imports in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (0.4.0)\n",
      "Requirement already satisfied: tqdm in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (3.1.6)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (8.10.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (2.9.0.post0)\n",
      "Requirement already satisfied: haystack-experimental in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (9.1.2)\n",
      "Requirement already satisfied: networkx in /home/SujayCS/.local/lib/python3.10/site-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (2.6.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (2.32.3)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from haystack-ai>=2.11.0->elasticsearch-haystack) (4.23.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from aiohttp->elasticsearch-haystack) (1.20.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from aiohttp->elasticsearch-haystack) (0.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from aiohttp->elasticsearch-haystack) (1.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/SujayCS/.local/lib/python3.10/site-packages (from aiohttp->elasticsearch-haystack) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from aiohttp->elasticsearch-haystack) (5.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/SujayCS/.local/lib/python3.10/site-packages (from aiohttp->elasticsearch-haystack) (6.4.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from aiohttp->elasticsearch-haystack) (2.6.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->elasticsearch-haystack) (25.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/lib/python3/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch<9,>=8->elasticsearch-haystack) (1.26.5)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from elastic-transport<9,>=8.15.1->elasticsearch<9,>=8->elasticsearch-haystack) (2020.6.20)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.56.1->haystack-ai>=2.11.0->elasticsearch-haystack) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.56.1->haystack-ai>=2.11.0->elasticsearch-haystack) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.56.1->haystack-ai>=2.11.0->elasticsearch-haystack) (0.28.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.56.1->haystack-ai>=2.11.0->elasticsearch-haystack) (4.8.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from openai>=1.56.1->haystack-ai>=2.11.0->elasticsearch-haystack) (0.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from posthog!=3.12.0->haystack-ai>=2.11.0->elasticsearch-haystack) (2.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from posthog!=3.12.0->haystack-ai>=2.11.0->elasticsearch-haystack) (1.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from pydantic->haystack-ai>=2.11.0->elasticsearch-haystack) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from pydantic->haystack-ai>=2.11.0->elasticsearch-haystack) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from pydantic->haystack-ai>=2.11.0->elasticsearch-haystack) (0.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->haystack-ai>=2.11.0->elasticsearch-haystack) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->haystack-ai>=2.11.0->elasticsearch-haystack) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->haystack-ai>=2.11.0->elasticsearch-haystack) (2.0.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->haystack-ai>=2.11.0->elasticsearch-haystack) (2024.10.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->haystack-ai>=2.11.0->elasticsearch-haystack) (0.22.3)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->haystack-ai>=2.11.0->elasticsearch-haystack) (0.36.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.56.1->haystack-ai>=2.11.0->elasticsearch-haystack) (1.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai>=2.11.0->elasticsearch-haystack) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.56.1->haystack-ai>=2.11.0->elasticsearch-haystack) (0.14.0)\n",
      "ERROR: unknown command \"elasticsearch-haystack\"\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub in /home/SujayCS/.local/lib/python3.10/site-packages (0.30.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from huggingface_hub) (2025.3.2)\n",
      "Requirement already satisfied: filelock in /home/SujayCS/.local/lib/python3.10/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (1.26.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface_hub>=0.27.0 in /home/SujayCS/.local/lib/python3.10/site-packages (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from huggingface_hub>=0.27.0) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from huggingface_hub>=0.27.0) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.27.0) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.27.0) (4.12.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.27.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from huggingface_hub>=0.27.0) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/SujayCS/.local/lib/python3.10/site-packages (from huggingface_hub>=0.27.0) (3.18.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.27.0) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.27.0) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub>=0.27.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub>=0.27.0) (3.4.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: streamlit in /home/SujayCS/.local/lib/python3.10/site-packages (1.45.0)\n",
      "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (20.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.4.2)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (5.29.4)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/lib/python3/dist-packages (from streamlit) (8.0.3)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /home/SujayCS/.local/lib/python3.10/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: jinja2 in /home/SujayCS/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /home/SujayCS/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.38.0)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/SujayCS/.local/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas<3,>=1.4.0->streamlit) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (1.26.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.27->streamlit) (2020.6.20)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/SujayCS/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/lib/python3/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.1.0)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install haystack-ai\n",
    "!{sys.executable} -m pip install elasticsearch-haystack \n",
    "!{sys.executable} -m pip elasticsearch-haystack\n",
    "!{sys.executable} -m pip install huggingface_hub\n",
    "!{sys.executable} -m pip  install \"huggingface_hub>=0.27.0\"\n",
    "!{sys.executable} -m pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f90b62e-316c-4f01-a82f-a84fcdd44a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from haystack import Pipeline\n",
    "from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchBM25Retriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.utils import Secret\n",
    "from elasticsearch import Elasticsearch, NotFoundError\n",
    "from glob import glob\n",
    "import huggingface_hub\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf8bb5-def5-41bc-8cd8-9b8e557ad363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.1: Load Class Transcripts into Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6773d7f-1d39-46cb-a1eb-58be20378c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-07 21:03:36--  https://github.com/CS639-Data-Management-for-Data-Science/s25/raw/main/p6/transcripts.zip\n",
      "Resolving github.com (github.com)... 140.82.114.3\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/CS639-Data-Management-for-Data-Science/s25/main/p6/transcripts.zip [following]\n",
      "--2025-05-07 21:03:37--  https://raw.githubusercontent.com/CS639-Data-Management-for-Data-Science/s25/main/p6/transcripts.zip\n",
      "185.199.108.133, 185.199.109.133, 185.199.110.133, ...tent.com)... \n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 290933 (284K) [application/zip]\n",
      "Saving to: â€˜transcripts.zip.6â€™\n",
      "\n",
      "transcripts.zip.6   100%[===================>] 284.11K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2025-05-07 21:03:37 (8.05 MB/s) - â€˜transcripts.zip.6â€™ saved [290933/290933]\n",
      "\n",
      "Archive:  transcripts.zip\n",
      "  inflating: transcripts/__MACOSX/._transcripts  \n",
      "  inflating: transcripts/transcripts/23 en-English-CS639_ Elasticsearch geo queries + Kibana.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._23 en-English-CS639_ Elasticsearch geo queries + Kibana.txt  \n",
      "  inflating: transcripts/transcripts/14 en-English-CS639_ MongoDB on Docker.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._14 en-English-CS639_ MongoDB on Docker.txt  \n",
      "  inflating: transcripts/transcripts/.DS_Store  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._.DS_Store  \n",
      "  inflating: transcripts/transcripts/11 en-English-CS639_ SQL Joins.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._11 en-English-CS639_ SQL Joins.txt  \n",
      "  inflating: transcripts/transcripts/16 en-English-CS639_ MongoDB Operators.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._16 en-English-CS639_ MongoDB Operators.txt  \n",
      "  inflating: transcripts/transcripts/7 en-English-CS639_ SQL on docker.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._7 en-English-CS639_ SQL on docker.txt  \n",
      "  inflating: transcripts/transcripts/12 en-English-CS639_ SQL window functions.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._12 en-English-CS639_ SQL window functions.txt  \n",
      "  inflating: transcripts/transcripts/2 en-English-CS639_ Deployment (Linux Shell).txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._2 en-English-CS639_ Deployment (Linux Shell).txt  \n",
      "  inflating: transcripts/transcripts/4 en-English-CS639_ Docker.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._4 en-English-CS639_ Docker.txt  \n",
      "  inflating: transcripts/transcripts/21 en-English-CS639_ Elasticsearch API intro.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._21 en-English-CS639_ Elasticsearch API intro.txt  \n",
      "  inflating: transcripts/transcripts/6.2 en-English-SQL 1_ Creating tables (post fire-alarm).txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._6.2 en-English-SQL 1_ Creating tables (post fire-alarm).txt  \n",
      "  inflating: transcripts/transcripts/1 en-English-CS639_ Course intro.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._1 en-English-CS639_ Course intro.txt  \n",
      "  inflating: transcripts/transcripts/17 en-English-CS639_ MongoDB Aggregation.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._17 en-English-CS639_ MongoDB Aggregation.txt  \n",
      "  inflating: transcripts/transcripts/20 en-English-CS639_ Elasticsearch intro.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._20 en-English-CS639_ Elasticsearch intro.txt  \n",
      "  inflating: transcripts/transcripts/22 en-English-CS639_ Elasticsearch_ Boosting, highlighting, and aggregations.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._22 en-English-CS639_ Elasticsearch_ Boosting, highlighting, and aggregations.txt  \n",
      "  inflating: transcripts/transcripts/6.1 en-English-CS639_ SQL 1_ Creating tables (part 1).txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._6.1 en-English-CS639_ SQL 1_ Creating tables (part 1).txt  \n",
      "  inflating: transcripts/transcripts/13 en-English-CS639_ Non-relational databases_ MongoDB.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._13 en-English-CS639_ Non-relational databases_ MongoDB.txt  \n",
      "  inflating: transcripts/transcripts/15 en-English-CS639_ MongoDB API.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._15 en-English-CS639_ MongoDB API.txt  \n",
      "  inflating: transcripts/transcripts/10 en-English-CS639_ SQL subqueries.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._10 en-English-CS639_ SQL subqueries.txt  \n",
      "  inflating: transcripts/transcripts/8 en-English-CS639_ Relational Algebra (RA).txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._8 en-English-CS639_ Relational Algebra (RA).txt  \n",
      "  inflating: transcripts/transcripts/3 en-English-CS639_ Deployment (Linux Pipelines).txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._3 en-English-CS639_ Deployment (Linux Pipelines).txt  \n",
      "  inflating: transcripts/transcripts/5 en-English-CS639_ Relational Database Management Systems (RDBMS).txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._5 en-English-CS639_ Relational Database Management Systems (RDBMS).txt  \n",
      "  inflating: transcripts/transcripts/18 en-English-CS639_ MongoDB Geospatial Operators.txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._18 en-English-CS639_ MongoDB Geospatial Operators.txt  \n",
      "  inflating: transcripts/transcripts/9 en-English-CS639_ Basic SQL queries (partial lecture).txt  \n",
      "  inflating: transcripts/__MACOSX/transcripts/._9 en-English-CS639_ Basic SQL queries (partial lecture).txt  \n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/CS639-Data-Management-for-Data-Science/s25/raw/main/p6/transcripts.zip\n",
    "!unzip -o transcripts.zip -d transcripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c6a24e8-869b-4294-9af1-7d642ac0c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_pwd = \"1fVO6RuC\"\n",
    "client = Elasticsearch(hosts=\"http://localhost:9200\", basic_auth=(\"elastic\", elastic_pwd))\n",
    "\n",
    "index_name = \"cs639_lectures\"\n",
    "\n",
    "try:\n",
    "    client.indices.delete(index=index_name)\n",
    "except NotFoundError:\n",
    "    print(\"Index doesn't exist!\")\n",
    "\n",
    "client.indices.create(index=index_name)\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    hosts=\"http://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", elastic_pwd),\n",
    "    index=index_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4c5f0b-99d3-4fb8-af52-a0b27271ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_paths = [f for f in glob(\"transcripts/transcripts/*.txt\") if not f.endswith(\".DS_Store\")]\n",
    "text_file_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c7cb19-86d1-4e7c-9d8b-0da0be3a94dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'writer': {'documents_written': 901}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_pipeline = Pipeline()\n",
    "index_pipeline.add_component(\"converter\", TextFileToDocument())\n",
    "index_pipeline.add_component(\"splitter\", DocumentSplitter(split_by=\"word\", split_length=150))\n",
    "index_pipeline.add_component(\"writer\", DocumentWriter(document_store))\n",
    "\n",
    "index_pipeline.connect(\"converter\", \"splitter\")\n",
    "index_pipeline.connect(\"splitter\", \"writer\")\n",
    "\n",
    "index_pipeline.run({\"converter\": {\"sources\": text_file_paths}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68404221-ab93-413b-ad90-7141543a5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "<|system|>\n",
    "You are a helpful teaching assistant for the CS 639 Data Management for Data Science course at UWâ€“Madison.<|end|>\n",
    "<|user|>\n",
    "Given the following lecture materials, answer the question clearly and concisely.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ query }}<|end|>\n",
    "<|assistant|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e54181-a30b-4760-89f6-7d21744856fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"huggingface_token\", \"r\") as FH:\n",
    "    data = FH.read()\n",
    "    huggingface_token = data.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d218ae82-646d-4f36-9068-e64504a14391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=huggingface_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c679e7-1ca1-499c-add5-2df436ea760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = ElasticsearchBM25Retriever(document_store=document_store)\n",
    "generator = HuggingFaceAPIGenerator(\n",
    "    api_type=\"serverless_inference_api\",\n",
    "    api_params={\"model\": \"microsoft/Phi-3.5-mini-instruct\", \"max_new_tokens\": 300 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b425d0a-f810-4ce9-82cf-7bd47c3e70c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PromptBuilder has 2 prompt variables, but `required_variables` is not set. By default, all prompt variables are treated as optional, which may lead to unintended behavior in multi-branch pipelines. To avoid unexpected execution, ensure that variables intended to be required are explicitly set in `required_variables`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x74e60ce29720>\n",
       "ðŸš… Components\n",
       "  - retriever: ElasticsearchBM25Retriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: HuggingFaceAPIGenerator\n",
       "ðŸ›¤ï¸ Connections\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1020df57-0bef-4b7b-b5cb-70051ffb44e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(query):\n",
    "    assert rag_pipeline is not None\n",
    "    res = rag_pipeline.run({\n",
    "        \"prompt_builder\": {\"query\": query},\n",
    "        \"retriever\": {\"query\": query}\n",
    "    })\n",
    "    return res['llm']['replies'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf83087-99db-4675-87b5-e536a45c31da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SujayCS/.local/lib/python3.10/site-packages/huggingface_hub/inference/_client.py:2288: FutureWarning: `stop_sequences` is a deprecated argument for `text_generation` task and will be removed in version '0.28.0'. Use `stop` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Can you tell me what the six projects covered in CS 639 Data Management for Data Science are and what tools each one focuses on in less than a 100 words?\n",
      "Response: 1. Setting up GCP VM: Focuses on Google Cloud Platform, specifically creating a small instance.\n",
      "2. Data storage types: Explores RDBMS, NoSQL DBMS, OODBMS, and graph databases.\n",
      "3. Data management systems: Introduces AWS Glue and Apache Atlas for cataloging and managing data.\n",
      "4. Basic Linux and Docker commands: Covers essential Linux commands and Docker environment setup for programming.\n",
      "5. Data organization tools: Teaches various tools for data storage and management.\n",
      "6. Data analysis and storytelling: Involves predictive analysis, data dashboards, and data storytelling techniques.\n",
      "\n",
      "(Note: The provided context does not list six specific projects but rather outlines topics and tools relevant to the course CS 639.)\n",
      "\n",
      "Top 3 Documents: [Document(id=a28c61bbdb2e5b935cfa3f663d0118e87209af5a103bc017b0cd5c7064b336e7, content: 'of data\n",
      "cataloging based systems, a couple of them are AWS\n",
      "Glue and Apache Atlas. Any questions abou...', meta: {'file_path': '1 en-English-CS639_ Course intro.txt', 'source_id': '7e2be5f54a0f35899052b2573449be38103de171f94c1013965f9a02f813aab1', 'page_number': 1, 'split_id': 37, 'split_idx_start': 33950}, score: 27.62721), Document(id=b63d423e586a1776e1e1ee568f9387640665df4bfa0f27f341bead850e8e4595, content: 'exactly is this course\n",
      "trying to teach you? Hopefully, how to\n",
      "effectively use various data organizat...', meta: {'file_path': '1 en-English-CS639_ Course intro.txt', 'source_id': '7e2be5f54a0f35899052b2573449be38103de171f94c1013965f9a02f813aab1', 'page_number': 1, 'split_id': 2, 'split_idx_start': 1803}, score: 27.59001), Document(id=82a8712f30e8944bf506e4f504285bd6e473b87cd62d3b37c22896573bcfc948, content: 'Let's see. We have three\n",
      "sophomores. That's awesome. And majority of\n",
      "you, as I expected, are seniors...', meta: {'file_path': '1 en-English-CS639_ Course intro.txt', 'source_id': '7e2be5f54a0f35899052b2573449be38103de171f94c1013965f9a02f813aab1', 'page_number': 1, 'split_id': 12, 'split_idx_start': 10402}, score: 27.301756)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Can you tell me what the six projects covered in CS 639 Data Management for Data Science are and what tools each one focuses on in less than a 100 words?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    response = generate(query)\n",
    "    top_docs = retriever.run(query=query)[\"documents\"][:3]\n",
    "    print(f\"Query: {query}\\nResponse: {response}\\n\")\n",
    "    print(f\"Top 3 Documents: {top_docs}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2df97-c90e-4035-9742-1c07bd27bec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.2: Implement the Streamlit App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b4be48a-1c77-4466-807a-73e64f3b231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "\n",
    "import os\n",
    "from haystack import Pipeline\n",
    "from haystack_integrations.document_stores.elasticsearch import ElasticsearchDocumentStore\n",
    "from haystack_integrations.components.retrievers.elasticsearch import ElasticsearchBM25Retriever\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.components.generators import HuggingFaceAPIGenerator\n",
    "from haystack.components.converters import TextFileToDocument\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.utils import Secret\n",
    "from elasticsearch import Elasticsearch, NotFoundError\n",
    "from glob import glob\n",
    "import huggingface_hub\n",
    "import streamlit as st\n",
    "\n",
    "elastic_pwd = \"1fVO6RuC\"\n",
    "client = Elasticsearch(hosts=\"http://localhost:9200\", basic_auth=(\"elastic\", elastic_pwd))\n",
    "\n",
    "index_name = \"cs639_lectures\"\n",
    "\n",
    "try:\n",
    "    client.indices.delete(index=index_name)\n",
    "except NotFoundError:\n",
    "    print(\"Index doesn't exist!\")\n",
    "\n",
    "client.indices.create(index=index_name)\n",
    "\n",
    "document_store = ElasticsearchDocumentStore(\n",
    "    hosts=\"http://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", elastic_pwd),\n",
    "    index=index_name\n",
    ")\n",
    "\n",
    "text_file_paths = [f for f in glob(\"transcripts/transcripts/*.txt\") if not f.endswith(\".DS_Store\")]\n",
    "text_file_paths.sort()\n",
    "\n",
    "index_pipeline = Pipeline()\n",
    "index_pipeline.add_component(\"converter\", TextFileToDocument())\n",
    "index_pipeline.add_component(\"splitter\", DocumentSplitter(split_by=\"word\", split_length=150))\n",
    "index_pipeline.add_component(\"writer\", DocumentWriter(document_store))\n",
    "\n",
    "index_pipeline.connect(\"converter\", \"splitter\")\n",
    "index_pipeline.connect(\"splitter\", \"writer\")\n",
    "\n",
    "index_pipeline.run({\"converter\": {\"sources\": text_file_paths}})\n",
    "\n",
    "template = \"\"\"\n",
    "<|system|>\n",
    "You are a helpful teaching assistant for the CS 639 Data Management for Data Science course at UWâ€“Madison.<|end|>\n",
    "<|user|>\n",
    "Given the following lecture materials, answer the question clearly and concisely.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ query }}<|end|>\n",
    "<|assistant|>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"huggingface_token\", \"r\") as FH:\n",
    "    data = FH.read()\n",
    "    huggingface_token = data.strip()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=huggingface_token)\n",
    "\n",
    "retriever = ElasticsearchBM25Retriever(document_store=document_store)\n",
    "generator = HuggingFaceAPIGenerator(\n",
    "    api_type=\"serverless_inference_api\",\n",
    "    api_params={\"model\": \"microsoft/Phi-3.5-mini-instruct\", \"max_new_tokens\": 300 })\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"retriever\", retriever)\n",
    "rag_pipeline.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "rag_pipeline.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "def generate(query):\n",
    "    assert rag_pipeline is not None\n",
    "    res = rag_pipeline.run({\n",
    "        \"prompt_builder\": {\"query\": query},\n",
    "        \"retriever\": {\"query\": query}\n",
    "    })\n",
    "    print(res.keys())\n",
    "    return res['llm']['replies'][0]\n",
    "\n",
    "queries = [\n",
    "    \"Can you tell me what the six projects covered in CS 639 Data Management for Data Science are and what tools each one focuses on in less than a 100 words?\",\n",
    "    \"What are some of the topics covered in the course?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    response = generate(query)\n",
    "    top_docs = retriever.run(query=query)[\"documents\"][:3]\n",
    "    print(f\"Query: {query}\\nResponse: {response}\\n\")\n",
    "    print(f\"Top 3 Documents: {top_docs}\\n\")\n",
    "\n",
    "st.set_page_config(page_title=\"ðŸ’¬ Course Chatbot\", page_icon=\"ðŸ“˜\")\n",
    "st.title(\"ðŸ’¬ Course Chatbot\")\n",
    "st.caption(\"ðŸš€ Interactive Q&A with Elasticsearch, Haystack, and HuggingFace\")\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Show chat history\n",
    "for msg in st.session_state.messages:\n",
    "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "\n",
    "# Handle new user input\n",
    "if prompt := st.chat_input(\"Ask a question about the course transcripts\"):\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "\n",
    "    with st.spinner(\"Thinking...\"):\n",
    "        response = generate(prompt)\n",
    "\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    st.chat_message(\"assistant\").write(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b2b2b-f64d-464c-958e-0859e918eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3.3: Compare Fine-Tuning vs RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c24f9533-ff6a-4bc5-8a1c-71fcc5f508d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are some of the topics covered in the course?\n",
      " Response: The course covers a variety of topics including basic Linux commands, Docker commands, relational database management, SQL, NoSQL with a focus on MongoDB, data cataloging systems like AWS Glue and Apache Atlas, data warehouses, data lakes, semantic layer, knowledge graphs, Apache Iceberg system, ETL vs ELT, data pipelines, predictive analysis using boosting and time series techniques, vector databases, advanced visualization topics like sunburst plots, dashboards, data storytelling, and prompt engineering.\n",
      "\n",
      "Query: What is the course code number for Data Management for Data Science?\n",
      " Response: The course code number for Data Management for Data Science is CS 639.\n",
      "\n",
      "Query: What NoSQL database was the main focus of project P2 in CS639?\n",
      " Response: The main focus of Project P2 in CS639 was MySQL, which is a type of relational database management system (RDBMS).\n",
      "\n",
      "Query: Can you explain window functions as taught in this course?\n",
      " Response: Window functions, as taught in this course, are special types of SQL functions that allow you to perform calculations across a specific subset of rows within a database table. Unlike aggregate functions, which collapse the rows into a single result (e.g., SUM, AVG), window functions maintain the original rows and provide a way to calculate statistics for each row in relation to other rows.\n",
      "\n",
      "Here are the key concepts and clauses associated with window functions:\n",
      "\n",
      "1. Over Clause: This clause defines the window or partition over which the function will be applied. It determines which rows are considered for the calculation.\n",
      "\n",
      "2. Order By Clause: This clause specifies the order of rows within the window. It is used in conjunction with the over clause to define the order in which the rows are processed.\n",
      "\n",
      "3. Partition By Clause: This clause divides the original table into partitions, where each partition contains rows with the same values for the specified columns. Each partition is treated independently when applying window functions.\n",
      "\n",
      "4. Aggregate Functions: These are functions that perform calculations on a set of values, such as SUM, AVG, COUNT, MIN, and MAX. Window functions can be used with aggregate functions to calculate statistics for each row based on the window defined by the over, order by, and partition by clauses.\n",
      "\n",
      "5. Window Frames: Window frames define the subset of rows within a window that are used for calculations. Common window frames include ROWS UNBOUNDED PRECEDING, ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW, and ROWS BETWEEN CURRENT ROW AND UNBOUNDED FOLLOWING.\n",
      "\n",
      "6. Ranking Functions: These are specific types of window functions that assign a rank to each row within a window based on a specified order. Examples include RANK, DENSE_RANK, and ROW_NUMBER.\n",
      "\n",
      "In summary, window functions enable you to perform calculations on a subset of rows within a table, while maintaining the original rows. They are useful for analyzing data in a more nuanced way, such as calculating running totals, moving averages, or ranking rows based on specific criteria. The over, order by, and partition by clauses, along with window frames and ranking functions, provide the necessary tools to define and manipulate these subsets\n",
      "\n",
      "Query: What SQL query clauses did we learn about in this course?\n",
      " Response: In this course, we learned about the following SQL query clauses:\n",
      "\n",
      "1. SELECT clause: Used for projection, which enables us to select specific columns or all columns from a table.\n",
      "\n",
      "2. FROM clause: Specifies the relation name (table) from which data is retrieved.\n",
      "\n",
      "3. WHERE clause: Used for filtering data based on specific conditions.\n",
      "\n",
      "4. GROUP BY clause: Groups rows that have the same values in specified columns into summary rows.\n",
      "\n",
      "5. HAVING clause: Used to filter groups based on conditions that involve aggregate functions.\n",
      "\n",
      "6. ORDER BY clause: Used to sort the result set in ascending or descending order based on one or more columns.\n",
      "\n",
      "7. OVER clause: Used with window functions to define a window or partition over which the function operates.\n",
      "\n",
      "8. PARTITION BY clause: Used with window functions to divide the result set into partitions based on specified columns.\n",
      "\n",
      "9. WINDOW clause: Used with window functions to define the window or partition over which the function operates.\n",
      "\n",
      "These clauses are essential for writing effective SQL queries and understanding how data is organized and manipulated in a database.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What are some of the topics covered in the course?\",\n",
    "    \"What is the course code number for Data Management for Data Science?\",\n",
    "    \"What NoSQL database was the main focus of project P2 in CS639?\",\n",
    "    \"Can you explain window functions as taught in this course?\",\n",
    "    \"What SQL query clauses did we learn about in this course?\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    response = generate(query)\n",
    "    # top_docs = retriever.run(query=query)[\"documents\"][:3]\n",
    "    print(f\"Query: {query}\\n Response: {response}\\n\")\n",
    "    # print(f\"Top 3 Documents: {top_docs}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61b7b848-fabe-4cce-803c-7ca23cc35336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYes, the RAG model performed much better on new or unseen queries (e.g., Questions 4 and 5).\\nIt was able to retrieve relevant documents from the transcripts and generate answers aligned with actual course material.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which approach gave more accurate responses?\n",
    "\n",
    "\"\"\"\n",
    "The RAG approach appears to be giving more accurate responses in general. \n",
    "However, this is not always the case as seen by question 3 where the fine-tuned model managed to identify that P2 was based on  \n",
    "MongoDB but the RAG model failed to identify this.\n",
    "However, the responses given to questions 1,4,5 are much better when using the RAG approach comapred to the fine-tuned model.\n",
    "Both approaches answered question 2 correctly.\n",
    "\"\"\"\n",
    "\n",
    "# Did the fine-tuned model hallucinate information?\n",
    "\"\"\"\n",
    "Yes. In Questions 1, 4, and 5, the fine-tuned model produced hallucinated or generic content that did not reflect CS639 accurately.\n",
    "It often defaulted to common CS course topics instead of what was actually taught.\n",
    "\"\"\"\n",
    "\n",
    "# Was RAG better at answering new/unseen questions?\n",
    "\"\"\"\n",
    "Yes, the RAG model performed much better on new or unseen queries (e.g., Questions 4 and 5).\n",
    "It was able to retrieve relevant documents from the transcripts and generate answers aligned with actual course material.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ccf80-b6ba-49be-90e4-935afd1e5687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
